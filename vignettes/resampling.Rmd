---
title: "Standard errors"
author: "Robert Maier"
date: "`r Sys.Date()`"
output:
  rmarkdown::html_vignette:
    toc: true
    toc_depth: 2
vignette: >
  %\VignetteIndexEntry{Standard errors}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
---

**Under construction**


## Quantifying uncertainty

The estimates produced by ADMIXTOOLS 2 (and by any other software) have high, but still limited precision, and it's often important to know what those limits are. There are several reasons why there is uncertainty in an estimate, but the two major ones in our case are the random sampling of individuals, and the random sampling (or rather the random drift) of SNPs: How different would the results be if we had used DNA from different individuals (from the same populations)? And how different would the results be if we could replay the same history, while letting the SNPs drift randomly another time?

We can answer these questions with resampling procedures such as jackknife and bootstrap. The original ADMIXTOOLS software uses jackknife to estimate standard errors of f-statistic estimates and other parameters, while ADMIXTOOLS 2 can also compute bootstrap standard errors. See *add section* for a comparison of the two methods. Unless otherwhise mentioned, standard errors estimate the uncertainty due to the random sampling of SNPs, although ADMIXTOOLS 2 also has functions that estimate the uncertainty due to the random sampling of individuals.



## Standard errors and hypothesis testing

Let's say we want to know whether populations $A$ and $B$ form a clade relative to $C$ and $D$. We can reject the null hypothesis that they do form a clade if $f_4(A, B; C, D)$ significantly deviates from zero -- if there is a significant covariance between the allele frequency differences $A-B$ and $C-D$.

To test whether this covariance is significant, we have to estimate its standard error, which will allow us to calculate a *p*-value -- the probability to observe an $f_4$ statistic of that or greater magnitude under the null hypothesis that the two population pairs form a clade and that the true covariance is zero.


## Bootstrap standard errors

The idea behind jackknife and bootstrap is that while it's impossible to know with certainty how different a result would be if we had different data, we can make an educated guess by analyzing many different subsets of our data. In the case of jackknife, the subsets are generated by leaving out each sample at a time, and for bootstrap they are generated by repeatedly resampling with replacement until the total number of samples is reached. In our case "samples" are usually blocks of SNPs.

We then calculate whichever statistic we're interested in on each of the subsets, resulting in $n$ subset-statistics $s_i$. From the variation in $s_i$ we can estimate the standard error.

For jackknife, the squared standard error, $\sigma^2$, is given by

$$\sigma^2 = \frac{n-1}{n} \sum_{i=1}^n (\mu - s_i)^2$$

and for bootstrap, where the $s_i$ are more different from each other, the squared standard error estimate is just the variance across $s_i$:

$$\sigma^2 = \frac{1}{n-1} \sum_{i=1}^n (\mu - s_i)^2$$

In both cases $\mu$ is the mean across $s_i$: $\mu = \frac{1}{n} \sum_{i=1}^n s_i$

<br>



## Block-jackknife standard errors

We can't actually use the approach described so far because SNPs do not drift independently of each other. While there are tens of millions of common SNPs in the human genome, the number of independent SNPs is closer to 50,000. If we don't account for that, we underestimate the true standard errors by orders of magnitude, leading to many false positive results.

The non-independence of SNPs (linkage disequilibrium) is mostly limited to SNPs in close proximity which are not separated by recombination hotspots. If we take two SNPs separated by 5 centiMorgan or more, they are usually independent of each other. So while we can't use the standard jackknife to get standard error estimates by leaving out each SNP at a time, we can divide the genome into blocks of 5 centiMorgan and leave out each block at a time. This complicates things a bit because some blocks have more SNPs than others, and should be weighted appropriately.

The actual standard error estimate is given by



<!-- $$\sigma^2 = \frac{1}{n} \sum_{i=1}^n (\frac{tot - s_i}{l_i} + s_i - est) / sqrt(\frac{1}{l_i}-1)$$ -->


<!-- $$\sigma^2 = \frac{1}{n} \sum_{i=1}^n (\frac{\sum_{i=1}^n s_i * l_i}{l_i} - \frac{s_i}{l_i} + \frac{s_i l_i}{l_i} - \frac{\sum_{i=1}^n s_i}{n}) / sqrt(\frac{1}{l_i}-1)$$ -->



<!-- The subsampling of SNPs in blocks (sepcifically block jackknife) is already used throughout all AdmixTools programs to compute standard erorrs. Here, the `resample_snps` functions generalize this approach in two ways. First, they evaluate and returns *all* model parameters for each set of resampled SNP blocks. Second, they provide the option to do bootstrap resampling (resampling blocks with replacement while keeping the total number of blocks fixed) rather than jackknife resampling (leaving one block out at a time). The advantage of bootstrap over jackknife resampling is that bootstrap resampling is less likely to underestimate the true variability in the presence of a few, large outliers. The disadvantage is that it is inherently stochastic and doesn't give the same results each time. Bootstrapping also makes it necessary to evaluate the whole model a large number of times, while jackknifing can be much faster, at least when computing only simple statistics. -->

<!-- Note that the bootstrap and jackknife resampling distributions are on different scales: Bootstrap standard errors are the square root of the sampling variance, whereas jackknife standard errors are the square root of **n times** the sampling variance. -->

<!-- In following example, 1000 models with resampled SNP blocks are evaluated, and a histogram of the likelihood scores is plotted. -->

<!-- ```{r, eval = FALSE} -->
<!-- snpres = qpgraph_resample_snps(example_f2_blocks, graph = example_graph, boot = 1000) -->
<!-- hist(snpres$score, 100) -->
<!-- ``` -->


<!-- ### Resampling individuals -->

<!-- We can also test how robust a model is to changes in the individuals that make up a population. The `resample_inds` functions evaluate every model that results from excluding one individual, for each individual in populations with at least two individuals. -->

<!-- ```{r, eval = FALSE} -->
<!-- pops = get_leafnames(example_igraph)[c(1:3, rep(4,4), 5:7)] -->
<!-- indres = qpgraph_resample_inds(my_counts_dir, inds = inds, pops = pops, graph = example_graph) -->
<!-- ggplot(indres, aes(score, score)) + geom_text(aes(label = ind)) -->
<!-- ``` -->

<!-- For populations with many individuals, this can be used to compute jackknife standard errors for statistics of that population. -->

<!-- <br> -->







